{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('Model-v_FdXyLj': venv)",
   "metadata": {
    "interpreter": {
     "hash": "ce6c5e13534921f1b311ddcd67b5e37b3e390f1903127c3f1e22c4cea362d096"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data from https://www.floydhub.com/emilwallner/datasets/colornet\n",
    "# download data an put it in a folder in the root called \"data\"\n",
    "items = []\n",
    "for file in os.listdir(\"./data/images/Train/\"):\n",
    "    img_array = img_to_array(load_img(\"./data/images/Train/\" + file))\n",
    "    items.append(img_array)\n",
    "items = np.array(items)\n",
    "X_train = 1.0/255 * items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # splits the data into train and test sets\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(imgs_gray, imgs_ab, test_size=0.2, random_state=42, shuffle=True)\n",
    "# X_train.astype('float')\n",
    "# X_test.astype('float')\n",
    "# Y_train.astype('float')\n",
    "# Y_test.astype('float')\n",
    "# print(\"X_train \" + str(X_train.shape))\n",
    "# print(\"X_test \" + str(X_test.shape))\n",
    "# print(\"y_train \" + str(Y_train.shape))\n",
    "# print(\"y_test \" + str(Y_test.shape))\n",
    "\n",
    "# print(X_train.min())\n",
    "# print(X_train.max())\n",
    "\n",
    "# print(Y_train.min())\n",
    "# print(Y_train.max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the inceptionResNetV2 for prediction of large features of the images\n",
    "import tensorflow.compat.v1 as tf_compact\n",
    "tf_compact.disable_v2_behavior()\n",
    "inception = InceptionResNetV2(weights=None, include_top=True)\n",
    "inception.load_weights(\"./data/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\")\n",
    "inception.graph = tf_compact.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the prediction with inceptionResNet\n",
    "# them the prediction is embed into the imgs\n",
    "def embed_inception_prediction(img_unsized):\n",
    "    # resize the image to fit in the resNet\n",
    "    img_resized = []\n",
    "    for i in img_unsized:\n",
    "        img = resize(i, (299, 299, 3), mode='constant')\n",
    "        img_resized.append(img)\n",
    "    img_resized = np.array(img_resized)\n",
    "    # this prepares the data for the resNet\n",
    "    img_resized = preprocess_input(img_resized)\n",
    "    with inception.graph.as_default():\n",
    "        imgs_embed = inception.predict(img_resized)\n",
    "    return imgs_embed\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True\n",
    ")\n",
    "\n",
    "batch_size_number = 10 # batch\n",
    "\n",
    "def image_train_datagen(X_data, batch_size):\n",
    "    for batch_imgs in train_datagen.flow(X_data, batch_size=batch_size):\n",
    "\n",
    "        grayscale_for_embeding = gray2rgb(rgb2gray(batch_imgs))\n",
    "        embeding = embed_inception_prediction(grayscale_for_embeding)\n",
    "\n",
    "        lab_train = rgb2lab(batch_imgs)\n",
    "        l_batch = lab_train[:, :, :, 0]\n",
    "        l_batch = l_batch.reshape(l_batch.shape + (1,))\n",
    "\n",
    "        ab_batch = lab_train[:, :, :, 1:] / 128\n",
    "       \n",
    "        yield([l_batch, embeding], ab_batch)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_image_train_datagen(X_data, batch_size):\n",
    "#     for batch_imgs in train_datagen.flow(X_data, batch_size=batch_size):\n",
    "#         grayscale_for_embeding = gray2rgb(rgb2gray(batch_imgs))\n",
    "#         embeding = embed_inception_prediction(grayscale_for_embeding)\n",
    "\n",
    "#         lab_train = rgb2lab(batch_imgs)\n",
    "#         l_batch = lab_train[:, :, :, 0]\n",
    "#         l_batch = l_batch.reshape(l_batch.shape + (1,))\n",
    "#         print(l_batch.shape)\n",
    "\n",
    "#         ab_batch = lab_train[:, :, :, 1:] / 128\n",
    "#         print(l_batch.shape)\n",
    "#         print(l_batch[0])\n",
    "\n",
    "#         print(ab_batch.shape)\n",
    "#         print(ab_batch[0])\n",
    "#         return([l_batch, embeding], ab_batch)\n",
    "\n",
    "\n",
    "# data = np.array([X_train[0]])\n",
    "# print()\n",
    "# test = test_image_train_datagen(data, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.layers.core'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-fdbd7a4bb99a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRepeatVector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.core'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, concatenate, Activation, Dense, Dropout, Flatten, RepeatVector\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers.core import , Permute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_img = cv2.imread(\"./data/testImg.jpeg\")\n",
    "rgb_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "print (rgb_img.shape)\n",
    "\n",
    "display(rgb_img)\n",
    "rgb_img.astype(\"uint8\")\n",
    "img_lab = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2LAB)\n",
    "img_lab = rgb2lab(test_img)\n",
    "img_l = img_lab[:, :, 0]\n",
    "img_ab = img_lab[:, :, 1:]\n",
    "print(img_l.max())\n",
    "print(img_l.min())\n",
    "print(img_ab.max())\n",
    "print(img_ab.min())\n",
    "display(img_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_batch = []\n",
    "y_batch = []\n",
    "\n",
    "x_batch.append(X_train[3])\n",
    "y_batch.append(Y_train[3])\n",
    "\n",
    "x_batch = np.array(x_batch)\n",
    "y_batch = np.array(y_batch)\n",
    "display(X_train[0])\n",
    "\n",
    "\n",
    "batch = 1\n",
    "\n",
    "\n",
    "def image_l_ab_datagen(x_train, y_train, batch_size):\n",
    "    for x_batch, y_batch in training_data_gen.flow(x_train, y_train, batch_size=batch_size):\n",
    "        x_batch = np.array(x_batch)\n",
    "        y_batch = np.array(y_batch)\n",
    "\n",
    "        gray_embeding = embed_inception_prediction(x_batch)\n",
    "        # to embeding here\n",
    "        \n",
    "        x_train = (x_batch * (100/255)) / 100\n",
    "        y_train = y_batch / 128\n",
    "        yield([x_train, gray_embeding], y_train)\n",
    "\n",
    "# imgs_rgb_normalized = []\n",
    "# for i in range(len(x_batch)):\n",
    "#     rgb_normalized = lab2RGB(x_batch[i], y_batch[i])\n",
    "#     # rgb = rgb * 255\n",
    "#     # rgb_normalized = 1.0/255 * rgb_normalized\n",
    "#     imgs_rgb_normalized.append(rgb_normalized)\n",
    "# imgs_rgb_normalized = np.array(imgs_rgb_normalized)\n",
    "# display(imgs_rgb_normalized[0])\n",
    "# gray_embeding = embed_inception_prediction(x_batch)\n",
    "# # to embeding here=\n",
    "# imgs_lab_normalized = rgb2lab(255 *imgs_rgb_normalized)\n",
    "# x_train = imgs_lab_normalized[:, :, :, 0]\n",
    "# x_train = x_train.reshape(x_train.shape + (1,))\n",
    "\n",
    "# y_train = imgs_lab_normalized[:, :, :, 1:]\n",
    "\n",
    "# y_train[0] =  y_train[0]\n",
    "# display(x_train[0])\n",
    "# img_display = lab2RGB(x_train[0], y_train[0])\n",
    "# display(img_display)\n",
    "\n",
    "# print(([x_train, gray_embeding], y_train))\n",
    "\n",
    "print(x_batch.shape)\n",
    "\n",
    "\n",
    "# embeding predictions\n",
    "gray_embeding = embed_inception_prediction(x_batch)\n",
    "\n",
    "imgs_lab = np.zeros((x_batch.shape[0], x_batch.shape[1], x_batch.shape[2], 3))\n",
    "print(imgs_lab.shape)\n",
    "imgs_lab[:, :, :, 0] = x_batch[:, :, :, 0]\n",
    "imgs_lab[:, :, :, 1:] = y_batch\n",
    "\n",
    "img_lab = imgs_lab[0]\n",
    "img_lab = img_lab.astype('uint8') \n",
    "print(imgs_lab[0].shape)\n",
    "img_rgb = cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "imgs_lab_norm = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)\n",
    "\n",
    "# imgs_l = imgs_lab_norm[:, :, 1:] / 128\n",
    "\n",
    "imgs_lab_norm_l = imgs_lab_norm[:, :, 0]\n",
    "imgs_lab_norm_ab = imgs_lab_norm[:, :, 1:]\n",
    "print(imgs_lab_norm_l.max())\n",
    "print(imgs_lab_norm_l.min())\n",
    "print(imgs_lab_norm_ab.max())\n",
    "\n",
    "print(imgs_lab_norm_ab.min())\n",
    "# print(imgs_l.max())\n",
    "# print(imgs_lab)\n",
    "\n",
    "\n",
    "x_train = (x_batch * (100/255)) / 100\n",
    "\n",
    "y_train = y_batch / 128\n",
    "print(y_train.max())\n",
    "print(y_train.min())\n",
    "display(x_train[0])\n",
    "y_train = y_train * 128\n",
    "\n",
    "x_train = (x_train * 100) * (255/100)\n",
    "\n",
    "img_to_display = lab2RGB(x_train[0], y_train[0])\n",
    "display(img_to_display)\n",
    "# yield([x_train, gray_embeding], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rbg_from_lab(gray_imgs, ab_imgs, n = 10):\n",
    "    \n",
    "    #create an empty array to store images\n",
    "    imgs = np.zeros((n, 224, 224, 3))\n",
    "    \n",
    "    imgs[:, :, :, 0] = gray_imgs[0:n:]\n",
    "    imgs[:, :, :, 1:] = ab_imgs[0:n:]\n",
    "    \n",
    "    #convert all the images to type unit8\n",
    "    imgs = imgs.astype(\"uint8\")\n",
    "    \n",
    "    #create a new empty array\n",
    "    imgs_ = []\n",
    "    \n",
    "    for i in range(0, n):\n",
    "        imgs_.append(cv2.cvtColor(imgs[i], cv2.COLOR_LAB2RGB))\n",
    "\n",
    "    #convert the image matrix into a numpy array\n",
    "    imgs_ = np.array(imgs_)\n",
    "\n",
    "    #print(imgs_.shape)\n",
    "    \n",
    "    return imgs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab2RGB(l, ab):\n",
    "    shape = (l.shape[0],l.shape[1],3)\n",
    "    img = np.zeros(shape)\n",
    "    img[:,:,0] = l[:,:,0]\n",
    "    img[:,:,1:] = ab\n",
    "    img = img.astype('uint8')\n",
    "    print(img.max())\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_LAB2RGB)\n",
    "    return img\n",
    "def display(img):\n",
    "    plt.figure()\n",
    "    plt.set_cmap('gray')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "img = lab2RGB(X_train[0], Y_train[0])\n",
    "display(img)\n",
    "    \n",
    "# testing_resacel = testing_resacel * 255\n",
    "# testing_res_a_b = testing_res_a_b * 255\n",
    "\n",
    "# img = l_ab_to_RGB(X_train[1], y_train[1])\n",
    "# # img = l_ab_to_RGB(testing_resacel, testing_res_a_b)\n",
    "# # img = np.resize(img, (256, 256, 3))\n",
    "# img = np.array(resize(img, (300, 300, 3), mode='constant'))\n",
    "# print(img.shape)\n",
    "\n",
    "# # testing_resacel = testing_resacel * 255\n",
    "# # display(testing_resacel)\n",
    "# display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading and image to predict\n",
    "\n",
    "test_img = cv2.imread(\"./data/ww1.jpeg\")\n",
    "rgb_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "print (rgb_img.shape)\n",
    "\n",
    "display(rgb_img)\n",
    "\n",
    "img_lab = rgb2lab(test_img)\n",
    "img_l = img_lab[:, :, 0]\n",
    "img_ab = img_lab[:, :, 1:]\n",
    "print(img_l.max())\n",
    "print(img_l.min())\n",
    "print(img_ab.max())\n",
    "print(img_ab.min())\n",
    "display(img_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}