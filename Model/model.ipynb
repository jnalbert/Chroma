{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('Model-v_FdXyLj': venv)",
   "metadata": {
    "interpreter": {
     "hash": "ce6c5e13534921f1b311ddcd67b5e37b3e390f1903127c3f1e22c4cea362d096"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D,InputLayer, Input, concatenate ,RepeatVector ,Reshape ,UpSampling2D\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data from https://www.floydhub.com/emilwallner/datasets/colornet\n",
    "# download data an put it in a folder in the root called \"data\"\n",
    "items = []\n",
    "num = 0\n",
    "for file in os.listdir(\"./data/images/Train/\"):\n",
    "    if (num < 250):\n",
    "\n",
    "        img_array = img_to_array(load_img(\"./data/images/Train/\" + file))\n",
    "        items.append(img_array)\n",
    "    num += 1\n",
    "items = np.array(items)\n",
    "X_train = 1.0/255 * items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, decode_predictions, preprocess_input\n",
    "inception = InceptionResNetV2(weights=None, include_top=True)\n",
    "inception.load_weights('./data/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "inception.graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To generate embeddings of 1000*1 by passing input images through InceptionResNetV2\n",
    "def create_inception_embedding(grayscaled_rgb):\n",
    "    grayscaled_rgb_resized = []\n",
    "    for i in grayscaled_rgb:\n",
    "        i = resize(i, (299, 299, 3), mode='constant')\n",
    "        grayscaled_rgb_resized.append(i)\n",
    "    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n",
    "    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
    "    with inception.graph.as_default():\n",
    "        embed = inception.predict(grayscaled_rgb_resized)\n",
    "    return embed\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_img = rgb2lab(X_train)\n",
    "x_batch = lab_img[:, :, :, 0].reshape(250,256,256,1)\n",
    "y_batch =lab_img[:, :, :, 1:] / 128\n",
    "\n",
    "\n",
    "\n",
    "#creating embeddings for Train data\n",
    "incept_em = create_inception_embedding(x_batch)\n",
    "embeddings = RepeatVector(32 * 32)(incept_em)\n",
    "layer_embedding_train = Reshape(([32, 32, 1000]))(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "# with tpu_strategy.scope():\n",
    "\n",
    "\n",
    "embed_input = Input(shape=(32, 32, 1000))\n",
    "encoder_input = Input(shape=(256, 256, 1,))\n",
    "\n",
    "encoder1 = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n",
    "encoder2 = Conv2D(128, (3,3), activation='relu', padding='same')(encoder1)\n",
    "encoder3 = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder2)\n",
    "encoder4 = Conv2D(256, (3,3), activation='relu', padding='same')(encoder3)\n",
    "encoder5 = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder4)\n",
    "encoder6 = Conv2D(512, (3,3), activation='relu', padding='same')(encoder5)\n",
    "encoder7 = Conv2D(512, (3,3), activation='relu', padding='same')(encoder6)\n",
    "encoder_output= Conv2D(256, (3,3), activation='relu', padding='same')(encoder7)\n",
    "#Fusion layer\n",
    "fusion1 = concatenate([encoder_output, embed_input], axis=3) \n",
    "fusion2 = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion1)\n",
    "fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion2)\n",
    "#Decoder layer\n",
    "decoder1 = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n",
    "decoder2 = UpSampling2D((2, 2))(decoder1)\n",
    "decoder3 = Conv2D(64, (3,3), activation='relu', padding='same')(decoder2)\n",
    "decoder4 = UpSampling2D((2, 2))(decoder3)\n",
    "decoder5 = Conv2D(32, (3,3), activation='relu', padding='same')(decoder4)\n",
    "decoder6 = Conv2D(16, (3,3), activation='relu', padding='same')(decoder5)\n",
    "decoder7 = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder6)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder7)\n",
    "\n",
    "model = Model(inputs=[encoder_input,embed_input], outputs=decoder_output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n",
    "model.fit(x=[x_batch,layer_embedding_train] ,y=y_batch, batch_size=5, epochs=1400,steps_per_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util functions\n",
    "\n",
    "def lab2RGB(l, ab):\n",
    "    shape = (l.shape[0],l.shape[1],3)\n",
    "    img = np.zeros(shape)\n",
    "    img[:,:,0] = l[:,:,0]\n",
    "    img[:,:,1:] = ab\n",
    "    img = img.astype('uint8')\n",
    "    print(img.max())\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_LAB2RGB)\n",
    "    return img\n",
    "def display(img):\n",
    "    plt.figure()\n",
    "    plt.set_cmap('gray')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "img = lab2RGB(X_train[0], Y_train[0])\n",
    "display(img)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading and image to predict\n",
    "\n",
    "test_img = cv2.imread(\"./data/ww1.jpeg\")\n",
    "rgb_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "print (rgb_img.shape)\n",
    "\n",
    "display(rgb_img)\n",
    "\n",
    "img_lab = rgb2lab(test_img)\n",
    "img_l = img_lab[:, :, 0]\n",
    "img_ab = img_lab[:, :, 1:]\n",
    "print(img_l.max())\n",
    "print(img_l.min())\n",
    "print(img_ab.max())\n",
    "print(img_ab.min())\n",
    "display(img_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_img = cv2.imread(\"./data/testImg.jpeg\")\n",
    "rgb_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "print (rgb_img.shape)\n",
    "\n",
    "display(rgb_img)\n",
    "rgb_img.astype(\"uint8\")\n",
    "img_lab = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2LAB)\n",
    "img_lab = rgb2lab(test_img)\n",
    "img_l = img_lab[:, :, 0]\n",
    "img_ab = img_lab[:, :, 1:]\n",
    "print(img_l.max())\n",
    "print(img_l.min())\n",
    "print(img_ab.max())\n",
    "print(img_ab.min())\n",
    "display(img_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}